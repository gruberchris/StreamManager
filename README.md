# Stream Manager

A self-service stream processing platform that decouples stream processing management from execution, allowing users to define, manage, and visualize streaming queries via a web interface.

**Now supports both ksqlDB and Apache Flink!** Choose your engine via configuration.

## Architecture

- **Frontend:** ASP.NET Core MVC (Razor Views) ‚Äî UI dashboard
- **Backend:** ASP.NET Core Web API ‚Äî Control plane and data plane
- **Database:** PostgreSQL ‚Äî Stores metadata about queries and status
- **Stream Engine:** Configurable ‚Äî Choose between ksqlDB or Apache Flink
- **Communication:** REST APIs + SignalR for real-time streaming

## Supported Stream Processing Engines

### ksqlDB (Confluent)

- **Best for:** Simple setup, smaller scale (fewer than 50 queries)
- **Pros:** Easy to configure, proven stability
- **Query Syntax:** ksqlDB SQL with `EMIT CHANGES`

### Apache Flink

- **Best for:** Large scale (more than 100 queries), advanced features
- **Pros:** Highly scalable, complex event processing, mature ecosystem
- **Query Syntax:** Standard Flink SQL (no `EMIT CHANGES`)

## Projects

### StreamManager.Api

The backend Web API that provides:

- **Stream Query Engine:** Abstracted interface supporting multiple engines (ksqlDB, Flink)
- **Ad-hoc Query Service:** Streams SQL query results via SignalR
- **Stream Management:** CRUD operations for persistent stream definitions
- **Query Validation:** Engine-specific SQL syntax validation
- **Topic Proxy Service:** Background service that consumes Kafka topics and broadcasts to SignalR groups
- **SignalR Hub:** Real-time communication for query streaming and topic preview

### StreamManager.Web

The frontend MVC web application that provides:

- **Query Tool:** Execute ad-hoc SQL queries with real-time streaming results
- **Stream Management:** Create, deploy, stop, and delete persistent streams
- **Live Preview:** View real-time data from deployed streams
- **Engine-Agnostic UI:** Works seamlessly with both ksqlDB and Flink

## Features

### Ad-Hoc Queries (/Query)

- CodeMirror-based SQL editor with syntax highlighting
- Real-time streaming of query results via SignalR
- Dynamic table generation based on a query schema
- Start/stop a query execution with cancellation support

### Stream Management (/Streams)

- Create persistent stream definitions
- Deploy streams to ksqlDB (CREATE STREAM AS SELECT)
- Stop running streams (TERMINATE a query)
- Delete stream definitions
- View stream status and metadata

### Live Preview (/Stream/{id})

- Real-time preview of data from deployed streams
- SignalR-based consumption of Kafka topics
- Connection status monitoring
- Message history with a scrollable view

## Database Schema

**StreamDefinitions Table:**

- `Id` (Guid) ‚Äî Primary key
- `Name` (string) ‚Äî Friendly stream name
- `SqlScript` (text) ‚Äî The SQL SELECT statement (engine-agnostic)
- `JobId` (string) ‚Äî Stream engine job identifier (ksqlDB query ID or Flink job ID)
- `StreamName` (string) ‚Äî Generated stream/table name in the engine
- `OutputTopic` (string) ‚Äî Kafka output topic name
- `IsActive` (bool) ‚Äî Stream deployment status
- `CreatedAt` (DateTime) ‚Äî Creation timestamp

## Getting Started

### Option 1: Run with ksqlDB

1. **Start Infrastructure:**
   ```bash
   docker-compose -f docker-compose.base.yml -f docker-compose.ksqldb.yml up -d
   ```

2. **Configure Engine (if needed):**
   
   Edit the `StreamManager.Api/appsettings.json` file:
   ```json
   {
     "StreamEngine": {
       "Provider": "KsqlDb",
       "KsqlDb": {
         "Url": "http://localhost:8088"
       }
     }
   }
   ```

3. **Run Database Migrations:**
   ```bash
   cd StreamManager.Api
   dotnet ef database update
   ```

4. **Start API Server:**
   ```bash
   cd StreamManager.Api
   dotnet run
   ```
   API will be available at: https://localhost:7068

5. **Start Web Application:**
   ```bash
   cd StreamManager.Web  
   dotnet run
   ```
   Web UI will be available at: https://localhost:7122

---

### Option 2: Run with Apache Flink

1. **Start Infrastructure:**
   ```bash
   docker-compose -f docker-compose.base.yml -f docker-compose.flink.yml up -d
   ```
   
   **‚è≥ Wait 60 seconds** for Flink to fully initialize before proceeding.

2. **Configure Engine:**
   
   Edit `StreamManager.Api/appsettings.json` file:
   ```json
   {
     "StreamEngine": {
       "Provider": "Flink",
       "Flink": {
         "SqlGatewayUrl": "http://localhost:8082",
         "RestApiUrl": "http://localhost:8088",
         "KafkaBootstrapServers": "localhost:9092",
         "KafkaFormat": "json"
       }
     }
   }
   ```

3. **Run Database Migrations:**
   ```bash
   cd StreamManager.Api
   dotnet ef database update
   ```

4. **Start API Server:**
   ```bash
   cd StreamManager.Api
   dotnet run
   ```
   API will be available at: https://localhost:7068

5. **Start Web Application:**
   ```bash
   cd StreamManager.Web  
   dotnet run
   ```
   Web UI will be available at: https://localhost:7122

6. **Verify Flink is Running:**
   ```bash
   # Check Flink JobManager
   curl http://localhost:8088/overview
   
   # Check Flink SQL Gateway
   curl http://localhost:8082/v1/info
   
   # Access Flink Web UI
   open http://localhost:8088
   ```

---

## üìö Example Setup

To run the examples in the documentation, see:

**[Orders Example Setup Guide](docs/ORDERS_EXAMPLE_SETUP.md)**

This guide walks you through:
1. Creating the Kafka topic
2. Setting up ksqlDB stream or Flink tables
3. Generating sample data
4. Running your first queries

All documentation examples assume you've completed this setup.

---

## Infrastructure Requirements

### Shared Services (Both Engines)

- **Kafka:** localhost:9092
- **Schema Registry:** http://localhost:8081
- **PostgreSQL:** localhost:5432
  - Database: `stream_manager_db`
  - User: `admin`
  - Password: `password`

### Engine-Specific Services

**ksqlDB:**
- **ksqlDB Server:** http://localhost:8088

**Flink:**
- **Flink JobManager (REST API):** http://localhost:8088
- **Flink SQL Gateway:** http://localhost:8082
- **Flink Web UI:** http://localhost:8088

---

## Switching Between Engines

To switch from ksqlDB to Flink (or vice versa):

1. **Stop all services:**
   ```bash
   docker-compose -f docker-compose.base.yml -f docker-compose.ksqldb.yml down
   # or
   docker-compose -f docker-compose.base.yml -f docker-compose.flink.yml down
   ```

2. **Update Configuration:**
   
   Edit the `StreamManager.Api/appsettings.json` file and change the `Provider`:
   - For ksqlDB: `"Provider": "KsqlDb"`
   - For Flink: `"Provider": "Flink"`

3. **Start New Infrastructure:**
   ```bash
   # For ksqlDB
   docker-compose -f docker-compose.base.yml -f docker-compose.ksqldb.yml up -d
   
   # OR for Flink
   docker-compose -f docker-compose.base.yml -f docker-compose.flink.yml up -d
   ```

4. **Restart API and Web apps**

**Note:** Existing stream definitions in the database will need their SQL syntax updated to match the new engine.

## SQL Syntax Differences

Understanding the syntax differences between engines is crucial:

| Feature                 | ksqlDB                               | Flink                                   |
|-------------------------|--------------------------------------|-----------------------------------------|
| **Streaming SELECT**    | `SELECT * FROM orders EMIT CHANGES;` | `SELECT * FROM orders;`                 |
| **Persistent Queries**  | `CREATE STREAM AS SELECT...`         | `INSERT INTO table SELECT...`           |
| **Window (Tumbling)**   | `WINDOW TUMBLING (SIZE 5 MINUTES)`   | `TUMBLE(time_col, INTERVAL '5' MINUTE)` |
| **LIMIT in Persistent** | ‚ùå Not allowed                        | ‚úÖ Allowed (bounded queries)             |

**üìö See [FLINK_MIGRATION.md](docs/FLINK_MIGRATION.md) for comprehensive SQL migration guide.**

---

## API Endpoints

### Stream Management

- `GET /api/streams` ‚Äî List all streams
- `POST /api/streams` ‚Äî Create new stream
- `GET /api/streams/{id}` ‚Äî Get stream details
- `PUT /api/streams/{id}` ‚Äî Update stream definition
- `POST /api/streams/{id}/deploy` ‚Äî Deploy stream to active engine
- `POST /api/streams/{id}/stop` ‚Äî Stop running stream
- `DELETE /api/streams/{id}` ‚Äî Delete stream

### Testing

- `POST /api/test/query` ‚Äî Test ad-hoc query execution
- `POST /api/test/direct` ‚Äî Direct engine connection test

### SignalR Hub (/hub/stream)

- `ExecuteAdHoc(string query)` ‚Äî Stream ad-hoc query results
- `ViewStream(string streamId)` ‚Äî Stream results from a deployed query
- `JoinStreamGroup(string topicName)` ‚Äî Subscribe to topic updates
- `LeaveStreamGroup(string topicName)` ‚Äî Unsubscribe from a topic
- `GetQueryLimits()` ‚Äî Get rate limit information

## Technology Stack

### Backend

- **.NET 10** ‚Äî Application framework
- **ASP.NET Core Web API** ‚Äî RESTful API
- **ASP.NET Core MVC** ‚Äî Web framework
- **SignalR** ‚Äî Real-time communication
- **Entity Framework Core** ‚Äî ORM with PostgreSQL
- **Confluent.Kafka** ‚Äî Kafka client library

### Stream Processing Engines

- **ksqlDB 7.6.0** ‚Äî Confluent's streaming database
- **Apache Flink 1.18** ‚Äî Distributed stream processing framework

### Frontend

- **Bootstrap 5** ‚Äî UI framework
- **CodeMirror** ‚Äî Code editor component
- **SignalR Client** ‚Äî Real-time updates

### Infrastructure

- **Docker & Docker Compose** ‚Äî Containerization
- **PostgreSQL 15** ‚Äî Metadata database
- **Apache Kafka (KRaft)** ‚Äî Event streaming platform
- **Confluent Schema Registry** ‚Äî Schema management

---

## Project Structure

```
StreamManager/
‚îú‚îÄ‚îÄ StreamManager.Api/              # Backend API
‚îÇ   ‚îú‚îÄ‚îÄ Controllers/                # REST API controllers
‚îÇ   ‚îú‚îÄ‚îÄ Services/                   # Business logic
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Engines/               # Stream engine implementations
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ KsqlDbEngine.cs    # ksqlDB implementation
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ FlinkEngine.cs     # Flink implementation
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Validators/            # Query validators
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ KsqlDbQueryValidator.cs
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ FlinkQueryValidator.cs
‚îÇ   ‚îú‚îÄ‚îÄ Hubs/                      # SignalR hubs
‚îÇ   ‚îî‚îÄ‚îÄ Configuration/             # Config models
‚îú‚îÄ‚îÄ StreamManager.Web/             # Frontend MVC
‚îÇ   ‚îú‚îÄ‚îÄ Controllers/               # MVC controllers
‚îÇ   ‚îú‚îÄ‚îÄ Views/                     # Razor views
‚îÇ   ‚îî‚îÄ‚îÄ wwwroot/                   # Static assets
‚îú‚îÄ‚îÄ docker-compose.base.yml        # Shared services (Kafka, Postgres)
‚îú‚îÄ‚îÄ docker-compose.ksqldb.yml      # ksqlDB service
‚îú‚îÄ‚îÄ docker-compose.flink.yml       # Flink services
‚îî‚îÄ‚îÄ docs/                          # Documentation
    ‚îú‚îÄ‚îÄ ENGINE_ABSTRACTION_PLAN.md
    ‚îú‚îÄ‚îÄ QUICK_START.md
    ‚îú‚îÄ‚îÄ FLINK_MIGRATION.md
    ‚îî‚îÄ‚îÄ ... (8 comprehensive guides)
```

---

## Documentation

Comprehensive documentation is available in the `/docs` folder:

| Document                                                                          | Description                               |
|-----------------------------------------------------------------------------------|-------------------------------------------|
| **[QUICK_START.md](docs/QUICK_START.md)**                                         | Fast setup guide for both engines         |
| **[QUICK_REFERENCE.md](docs/QUICK_REFERENCE.md)**                                 | Quick reference card for daily operations |
| **[ENGINE_ABSTRACTION_PLAN.md](docs/ENGINE_ABSTRACTION_PLAN.md)**                 | Architecture and design decisions         |
| **[PHASE4_IMPLEMENTATION.md](docs/PHASE4_IMPLEMENTATION.md)**                     | Flink implementation details              |
| **[FLINK_MIGRATION.md](docs/FLINK_MIGRATION.md)**                                 | SQL syntax migration guide                |
| **[COMPLETE_IMPLEMENTATION_SUMMARY.md](docs/COMPLETE_IMPLEMENTATION_SUMMARY.md)** | Full project summary                      |

---

## Key Features

### ‚ú® Multi-Engine Support

- **Configuration-based** engine selection (no code changes)
- **Engine-specific** SQL validation
- **Unified interface** ‚Äî same API for both engines

### üîÑ Real-Time Streaming

- **SignalR-based** result streaming
- **Live previews** of deployed streams
- **Rate limiting** to prevent resource exhaustion

### üéØ Query Management

- **Ad-hoc queries** ‚Äî Execute queries on-demand
- **Persistent queries** ‚Äî Deploy long-running streaming jobs
- **Query validation** ‚Äî Prevent invalid SQL before execution
- **Resource limits** ‚Äî Configurable query complexity limits

### üìä Stream Management

- **CRUD operations** for stream definitions
- **Deploy/Stop** control for persistent streams
- **Job tracking** ‚Äî Monitor running jobs
- **Status monitoring** ‚Äî Real-time stream health

### üõ°Ô∏è Safety Features

- **Query validation** ‚Äî Engine-specific syntax checking
- **Rate limiting** ‚Äî Prevent a query abuse
- **Resource limits** ‚Äî Max JOINs, windows, query length
- **Blocked keywords** ‚Äî Prevent dangerous operations

---

## Production Considerations

### Security

- [ ] Add authentication (e.g., OAuth, JWT)
- [ ] Enable HTTPS/TLS
- [ ] Secure database credentials (use secrets management)
- [ ] Implement authorization (role-based access)
- [ ] Enable audit logging

### Monitoring

- [ ] Set up Prometheus metrics
- [ ] Configure Grafana dashboards
- [ ] Monitor Flink/ksqlDB health
- [ ] Track a query performance
- [ ] Set up alerting (PagerDuty, Slack)

### Scalability

- [ ] Load balance API servers
- [ ] Scale Flink TaskManagers (if using Flink)
- [ ] Configure proper resource limits
- [ ] Set up PostgreSQL replication
- [ ] Implement connection pooling

### High Availability

- [ ] Deploy multiple API instances
- [ ] Use managed PostgreSQL (AWS RDS, Azure Database)
- [ ] Configure Kafka replication
- [ ] Set up health checks
- [ ] Implement graceful shutdown

---

## Troubleshooting

### Common Issues

**1. "Failed to connect to ksqlDB/Flink"**
```bash
# Check if services are running
docker ps

# View logs
docker logs ksqldb-server
docker logs flink-sql-gateway

# Verify connectivity
curl http://localhost:8088/info  # ksqlDB
curl http://localhost:8082/v1/info  # Flink
```

**2. "EMIT CHANGES is not valid Flink SQL syntax"**

- You're using ksqlDB syntax with Flink configured
- Remove `EMIT CHANGES` from your query

**3. "Database connection failed"**

```bash
# Check PostgreSQL
docker logs postgres-db

# Verify credentials in the appsettings.json file
# Default: Host=localhost;Database=stream_manager_db;Username=admin;Password=password
```

**4. SignalR connection fails**

- Ensure endpoint is `/hub/stream` (not `/hub/ksql`)
- Check CORS configuration
- Verify API is running and accessible

---

## Contributing

Contributions are welcome! The architecture is designed to be extensible:

1. **Add new engines** ‚Äî Implement `IStreamQueryEngine` interface
2. **Add validators** ‚Äî Implement `IQueryValidator` interface
3. **Enhance UI** ‚Äî Add features to StreamManager.Web
4. **Improve docs** ‚Äî Update documentation in `/docs`

---

## License

[Your License Here]

---

## Support

For issues, questions, or contributions:

- **Documentation:** Check the `/docs` folder
- **Quick Start:** [QUICK_START.md](docs/QUICK_START.md)
- **Issues:** Create a GitHub issue
- **Questions:** Refer to [QUICK_REFERENCE.md](docs/QUICK_REFERENCE.md)

---

**üéâ Stream Manager ‚Äì Now with dual-engine support for ksqlDB and Apache Flink!**

**Version:** 1.0.0  
**Last Updated:** December 7, 2025